"""Generate detailed cost and charges summary from broker fee data - DEMO VERSION.

Uses a specified LLM (e.g., GPT-4o, Claude 3 Opus) to analyze extracted PDF
text and broker definitions, producing a comprehensive summary of costs and
charges per broker.
"""
from __future__ import annotations

import argparse
import json
import sys
import os
import hashlib
import re
from pathlib import Path
import logging
from dataclasses import asdict
import time

PROJECT_ROOT = Path(__file__).resolve().parents[1]
SRC_PATH = PROJECT_ROOT / "src"
if str(SRC_PATH) not in sys.path:
    sys.path.insert(0, str(SRC_PATH))

from be_invest.config_loader import load_brokers_from_yaml
from be_invest.sources.llm_extract import extract_fee_records_via_llm
from be_invest.models import Broker, FeeRecord

DEFAULT_DATA_DIR = Path("data")
DEFAULT_BROKERS_PATH = DEFAULT_DATA_DIR / "brokers.yaml"
DEFAULT_PDF_TEXT_DIR = DEFAULT_DATA_DIR / "output" / "pdf_text"
DEFAULT_OUTPUT_DIR = DEFAULT_DATA_DIR / "output"

# Setup detailed logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


def get_text_filename_for_broker_source(broker_name: str, ds_description: str, url: str) -> str:
    """Recreate the exact filename generated by the /refresh-pdfs endpoint."""
    safe_broker_name = re.sub(r'[\s/]+', '_', broker_name)
    safe_desc = re.sub(r'[\s/]+', '_', ds_description or 'document')
    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
    return f"{safe_broker_name}_{safe_desc}_{url_hash}.txt"


def extract_all_fee_records(
    brokers_yaml_path: Path,
    pdf_text_dir: Path,
    cache_dir: Path | None = None,
    model: str = "claude-sonnet-4-20250514",
    skip_llm: bool = False,
) -> list[FeeRecord]:
    """Extract fee records from all brokers by linking brokers.yaml to text files."""
    logger.info("--- Starting Fee Extraction Stage ---")
    
    logger.info("Loading brokers from: %s", brokers_yaml_path)
    brokers = load_brokers_from_yaml(brokers_yaml_path)
    all_records: list[FeeRecord] = []

    logger.info("Using model: %s for extraction.", model)
    if not pdf_text_dir.exists():
        logger.error("PDF text directory not found: %s. Run the /refresh-pdfs endpoint first.", pdf_text_dir)
        return []

    for broker in brokers:
        if not broker.data_sources:
            logger.debug("Broker %s has no data sources defined. Skipping.", broker.name)
            continue

        for ds in broker.data_sources:
            if not ds.url:
                continue

            expected_filename = get_text_filename_for_broker_source(broker.name, ds.description, ds.url)
            text_file_path = pdf_text_dir / expected_filename

            if not text_file_path.exists():
                logger.warning("Text file not found for %s source: %s (expected %s)", broker.name, ds.url, expected_filename)
                continue

            try:
                text_content = text_file_path.read_text(encoding="utf-8")
                if not text_content.strip():
                    logger.debug("Skipping empty text file: %s", text_file_path)
                    continue
            except Exception as e:
                logger.error("Failed to read text file %s: %s", text_file_path, e)
                continue

            logger.info("Processing text file for %s: %s (%d chars)", broker.name, text_file_path.name, len(text_content))

            if skip_llm:
                logger.info("Skipping LLM extraction for %s due to --skip-llm flag.", broker.name)
                continue

            try:
                logger.info("Sending request to LLM for %s...", broker.name)
                start_time = time.time()
                records = extract_fee_records_via_llm(
                    text=text_content,
                    broker=broker.name,
                    source_url=ds.url,
                    model=model,
                    llm_cache_dir=cache_dir,
                    max_output_tokens=2000,
                    temperature=0.0,
                )
                end_time = time.time()
                logger.info("LLM call for %s completed in %.2f seconds.", broker.name, end_time - start_time)
                
                if records:
                    logger.info("Successfully extracted %d fee records for %s.", len(records), broker.name)
                    all_records.extend(records)
                else:
                    logger.warning("LLM returned no records for %s.", broker.name)

            except Exception as e:
                logger.error("LLM extraction failed for %s: %s", broker.name, e, exc_info=True)

    logger.info("--- Fee Extraction Stage Complete ---")
    return all_records


def generate_summary_via_llm(
    fee_records: list[FeeRecord],
    model: str = "claude-sonnet-4-20250514",
) -> str:
    """Generate a detailed summary of costs and charges using a specified LLM."""
    logger.info("--- Starting Summary Generation Stage ---")
    provider = "anthropic" if model.startswith("claude") else "openai"
    api_key_env = "ANTHROPIC_API_KEY" if provider == "anthropic" else "OPENAI_API_KEY"
    api_key = os.getenv(api_key_env)

    if not api_key:
        logger.error("%s API key not found in environment variable: %s", provider.title(), api_key_env)
        return ""

    logger.info("Preparing data for summary generation...")
    records_by_broker = {}
    for record in fee_records:
        records_by_broker.setdefault(record.broker, []).append(record)

    fee_data_text = "# Fee Records Extracted\n\n"
    for broker, records in sorted(records_by_broker.items()):
        fee_data_text += f"## {broker}\n"
        for i, r in enumerate(records, 1):
            fee_data_text += f"### Record {i}\n"
            fee_data_text += f"- Instrument Type: {r.instrument_type}\n"
            fee_data_text += f"- Order Channel: {r.order_channel}\n"
            fee_data_text += f"- Base Fee: {r.base_fee} {r.currency}\n"
            fee_data_text += f"- Variable Fee: {r.variable_fee}\n"
            fee_data_text += f"- Source: {r.source}\n"
            if r.notes:
                fee_data_text += f"- Notes: {r.notes}\n"
            fee_data_text += "\n"

    summary_prompt = f"""You are an expert financial analyst...
{fee_data_text}
Generate a professional, well-structured summary..."""

    logger.info("Sending request to LLM for final summary generation (this may take a moment)...")
    start_time = time.time()
    try:
        if provider == "anthropic":
            from anthropic import Anthropic
            client = Anthropic(api_key=api_key)
            response = client.messages.create(
                model=model,
                system="You are an expert financial analyst...",
                messages=[{"role": "user", "content": summary_prompt}],
                temperature=0.3,
                max_tokens=4000,
            )
            summary = response.content[0].text
        else:  # openai
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are an expert financial analyst..."},
                    {"role": "user", "content": summary_prompt}
                ],
                temperature=0.3,
                max_tokens=4000,
            )
            summary = response.choices[0].message.content or ""
        
        end_time = time.time()
        logger.info("LLM call for summary generation completed in %.2f seconds.", end_time - start_time)
        return summary
    except Exception as e:
        logger.error("Failed to generate summary: %s", e)
        return ""


def main():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--brokers", type=Path, default=DEFAULT_BROKERS_PATH)
    parser.add_argument("--pdf-text-dir", type=Path, default=DEFAULT_PDF_TEXT_DIR)
    parser.add_argument("--output", type=Path, default=DEFAULT_OUTPUT_DIR / "broker_summary.md")
    parser.add_argument("--cache-dir", type=Path, default=DEFAULT_DATA_DIR / "cache")
    parser.add_argument("--model", type=str, default="claude-sonnet-4-20250514", help="LLM to use (e.g., claude-sonnet-4-20250514, gpt-4o)")
    parser.add_argument("--extract-only", action="store_true")
    parser.add_argument("--skip-llm", action="store_true")
    parser.add_argument("--no-api", action="store_true")
    parser.add_argument("--log-level", choices=["DEBUG", "INFO", "WARNING", "ERROR"], default="INFO")
    args = parser.parse_args()

    logging.getLogger().setLevel(getattr(logging, args.log_level))
    logger.info("=================================================")
    logger.info("    Starting Broker Fee Summary Generation     ")
    logger.info("=================================================")
    
    fee_records = extract_all_fee_records(
        brokers_yaml_path=args.brokers,
        pdf_text_dir=args.pdf_text_dir,
        cache_dir=args.cache_dir,
        model=args.model,
        skip_llm=args.skip_llm,
    )

    if not fee_records:
        logger.error("No fee records were extracted. Aborting summary generation.")
        return 1

    logger.info("Extracted %d total fee records across all brokers.", len(fee_records))
    
    extracted_json_path = args.output.parent / "extracted_fees.json"
    logger.info("Saving extracted records to %s...", extracted_json_path)
    try:
        extracted_data = [asdict(r) for r in fee_records]
        extracted_json_path.write_text(json.dumps(extracted_data, indent=2, ensure_ascii=False), encoding="utf-8")
        logger.info("Successfully saved extracted records.")
    except Exception as e:
        logger.error("Failed to save extracted records: %s", e)

    if args.extract_only:
        logger.info("--- Extract-only mode enabled. Stopping now. ---")
        return 0

    if args.no_api:
        logger.warning("Skipping summary generation via LLM due to --no-api flag.")
        summary = "Summary generation was skipped."
    else:
        summary = generate_summary_via_llm(fee_records=fee_records, model=args.model)
        if not summary:
            logger.error("LLM API call failed or returned empty content. Aborting.")
            return 1

    logger.info("Saving final summary to %s...", args.output)
    args.output.parent.mkdir(parents=True, exist_ok=True)
    args.output.write_text(summary, encoding="utf-8")
    logger.info("Summary saved successfully.")
    
    logger.info("=================================================")
    logger.info("      Broker Fee Summary Generation Complete     ")
    logger.info("=================================================")
    print("\n" + summary)

    return 0


if __name__ == "__main__":
    sys.exit(main())
